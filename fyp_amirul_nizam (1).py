# -*- coding: utf-8 -*-
"""FYP AMIRUL NIZAM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1daU6orsSNw3e4NkpmAerA2MAUkhZzw9z

Data preprocessing
"""

import pandas as pd

# Read the CSV file
df = pd.read_csv('/content/drive/MyDrive/Fyp dataset/ROP_data .csv')

# Select the required columns
df = df[['Depth', 'WOB', 'SURF_RPM', 'ROP_AVG', 'PHIF', 'VSH', 'SW']]

# Handle missing values
df = df.dropna()  # Drop rows with missing values

# Handle outliers
z_scores = (df[['Depth', 'WOB', 'SURF_RPM', 'ROP_AVG', 'VSH', 'SW']] - df[['Depth', 'WOB', 'SURF_RPM', 'ROP_AVG', 'VSH', 'SW']].mean()) / df[['Depth', 'WOB', 'SURF_RPM', 'ROP_AVG', 'VSH', 'SW']].std()
df = df[(z_scores.abs() < 3).all(axis=1)]  # Keep rows where the absolute Z-score is less than 3

# Convert VSH and SW to percentage
df['VSH'] *= 100
df['SW'] *= 100

# Assuming PHIF is in decimal format, convert it to a manipulated variable between 0 and 100
df['PHIF'] = df['PHIF'] * 100

# Print the preprocessed data
print(df)

"""Training and Testing"""

from sklearn.model_selection import train_test_split

# Split the data into features (X) and target variable (y)
X = df[['Depth', 'WOB', 'SURF_RPM', 'ROP_AVG', 'PHIF']]
y = df[['VSH', 'SW']]

# Split the data into training, validation, and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)

#Features for the training set
X_train

#Target variables (VSH and SW) for the training set
y_train

#Features for the validation set
X_val

#Target variables (VSH and SW) for the validation set
y_val

#Features for the testing set
X_test

#Target variables (VSH and SW) for the testing set
y_test

df.shape

#view of dataset

df.head(30)
df.tail(30)

"""Feature selection"""

# Calculate correlation coefficients
correlation_matrix = df[['Depth', 'WOB', 'SURF_RPM', 'ROP_AVG', 'PHIF', 'SW', 'VSH']].corr()
vsh_correlations = correlation_matrix['VSH']

# Display correlation coefficients
print("Correlation with VSH:")
print(vsh_correlations)

phif_correlations = correlation_matrix[['WOB', 'SURF_RPM', 'ROP_AVG']]
print("Correlation with PHIF:")
print(phif_correlations)

from sklearn.ensemble import RandomForestRegressor

# Separate X and y
X = df[['WOB', 'SURF_RPM', 'ROP_AVG']]
y = df['PHIF']

# Fit Random Forest model
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X, y)

# Get feature importances
feature_importances = rf_model.feature_importances_

# Create DataFrame with feature importances
feature_importances_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
feature_importances_df = feature_importances_df.sort_values('Importance', ascending=False)

print("Feature Importance for PHIF:")
print(feature_importances_df)

"""Model Training"""

from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Assuming you have a pandas DataFrame named 'df' containing the data

# Define the algorithms and their hyperparameter ranges
algorithms = [
    ('Linear Regression', LinearRegression(), {}),
    ('Random Forest', RandomForestRegressor(), {'n_estimators': 100}),
    ('Support Vector Regression', SVR(), {'C': 1.0, 'kernel': 'linear'}),
    ('Multilayer Perceptron', MLPRegressor(), {'hidden_layer_sizes': [100, 100, 100]}),
    ('Decision Tree', DecisionTreeRegressor(), {'criterion': 'friedman_mse', 'min_samples_split': 2})
]

# Perform cross-validation and evaluate models
for name, model, hyperparams in algorithms:
    print(f"Model: {name}")
    features = ['WOB', 'SURF_RPM', 'ROP_AVG', 'PHIF']
    if name != 'Linear Regression':
        features.append('SW')
    X = df[features]
    y = df['VSH' if name != 'Decision Tree' else 'SW']

    # Hyperparameter tuning and cross-validation
    best_mse = float('inf')
    best_params = None
    for params in [hyperparams] if hyperparams else [{}]:
        model.set_params(**params)
        scores = -cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)
        avg_mse = scores.mean()
        if avg_mse < best_mse:
            best_mse = avg_mse
            best_params = params
    print(f"Best MSE: {best_mse}")
    print(f"Best Hyperparameters: {best_params}")

    # Train final model using best hyperparameters
    final_model = model
    final_model.set_params(**best_params)
    final_model.fit(X, y)

    # Make predictions
    y_pred = final_model.predict(X)

    # Calculate evaluation metrics
    mse = mean_squared_error(y, y_pred)
    mae = mean_absolute_error(y, y_pred)
    r2 = r2_score(y, y_pred)
    print(f"MSE: {mse}")
    print(f"MAE: {mae}")
    print(f"R-squared: {r2}")
    print()

import joblib

# Assuming 'final_model' is the trained model you want to save
model_name = 'decision_tree_model.joblib'
joblib.dump(final_model, model_name)
print(f"Trained model saved as '{model_name}'.")

"""Model Evaluation"""

import joblib

# Load the saved model
model_name = 'decision_tree_model.joblib'
loaded_model = joblib.load(model_name)

from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Make predictions on the testing set
y_pred = loaded_model.predict(X_test)
print (y_pred)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Calculate evaluation metrics
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Evaluation Metrics:")
print(f"MSE: {mse}")
print(f"MAE: {mae}")
print(f"R-squared: {r2}")

import matplotlib.pyplot as plt

# Visualize predicted values vs actual values
plt.scatter(y_test, y_pred)
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values')
plt.show()

# Save the model
joblib_file = "decision_tree_model.pkl"
joblib.dump(model, joblib_file)

from google.colab import files

# Download the file
files.download(joblib_file)